# -*- coding: utf-8 -*-
"""M357_MAP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IZ4Uk-hxrktwDr2eIUMXcyViDd2O29b_
"""

# ======================================
# 1. Instalación de librerías en Colab
# ======================================

# ======================================
# 2. Importaciones
# ======================================
import feedparser
import re
import json
import time
import os
from geopy.geocoders import Nominatim

# ======================================
# 3. Configuración
# ======================================
# Lista completa de TODOS tus feeds (inglés, español, francés, portugués, alemán, etc.).
# Esta lista la integramos con todos los enlaces que proporcionaste.
RSS_FEEDS = [
    # En inglés (ejemplo)
    "https://www.google.com/alerts/feeds/08823391955851607514/18357020651463187477",  # Freemasonry
    "https://www.google.com/alerts/feeds/08823391955851607514/434625937666013668",     # Grand Lodge
    "https://www.google.com/alerts/feeds/08823391955851607514/303056625914324165",     # Masonic Brotherhood
    "https://www.google.com/alerts/feeds/08823391955851607514/9378709536916495456",    # Masonic Lodge
    "https://www.google.com/alerts/feeds/08823391955851607514/17243776362555978691",   # Masonic Order
    "https://www.google.com/alerts/feeds/08823391955851607514/15847044508852608532",   # Masonic Temple

    # Adicionales (español, francés, alemán, portugués, etc.) que nos diste
    "https://www.google.com/alerts/feeds/08823391955851607514/6833079353494005014",
    "https://www.google.com/alerts/feeds/08823391955851607514/5572981003473119348",
    "https://www.google.com/alerts/feeds/08823391955851607514/17383807687186980718",
    "https://www.google.com/alerts/feeds/08823391955851607514/11043471059141282309",
    "https://www.google.com/alerts/feeds/08823391955851607514/13877290848809114470",
    "https://www.google.com/alerts/feeds/08823391955851607514/10413993926495102043",
    "https://www.google.com/alerts/feeds/08823391955851607514/2031900511198117844",
    "https://www.google.com/alerts/feeds/08823391955851607514/16568355059505461850",
    "https://www.google.com/alerts/feeds/08823391955851607514/16568355059505461178",
    "https://www.google.com/alerts/feeds/08823391955851607514/7760122889210870690",
    "https://www.google.com/alerts/feeds/08823391955851607514/15183025294765855574",
    "https://www.google.com/alerts/feeds/08823391955851607514/4297759070181606765",
    "https://www.google.com/alerts/feeds/08823391955851607514/11630540178333861502",
    "https://www.google.com/alerts/feeds/08823391955851607514/15251611368669093385",
    "https://www.google.com/alerts/feeds/08823391955851607514/9684782093161547179",
    "https://www.google.com/alerts/feeds/08823391955851607514/8744244600052796540",
    "https://www.google.com/alerts/feeds/08823391955851607514/357094683772830109",
    "https://www.google.com/alerts/feeds/08823391955851607514/13155130439785831467",
    "https://www.google.com/alerts/feeds/08823391955851607514/15809012670835506226",
    "https://www.google.com/alerts/feeds/08823391955851607514/14458568452294133843",
    "https://www.google.com/alerts/feeds/08823391955851607514/3528049070088672707",
    "https://www.google.com/alerts/feeds/08823391955851607514/11937818240173291166"
]

MASTER_JSON = "master_data.json"  # Acumula TODOS los artículos de cualquier idioma
OUTPUT_GEOJSON = "masoneria_alertas.geojson"

# Para geocodificación
USE_GEOCODING = True
geolocator = Nominatim(user_agent="masoneria_geolocator")

# ======================================
# 4. Funciones Auxiliares
# ======================================
def load_master_data():
    """Carga datos previos del archivo maestro (si existe)."""
    if os.path.isfile(MASTER_JSON):
        with open(MASTER_JSON, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_master_data(data):
    """Guarda la lista de artículos en el archivo maestro."""
    with open(MASTER_JSON, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def is_duplicate(entry, master_data):
    """Verifica si el 'link' ya existe en 'master_data'."""
    link_new = entry.get("link", "")
    for item in master_data:
        if item.get("link", "") == link_new:
            return True
    return False

def extract_possible_location(text):
    """
    Busca patrones 'in <Ciudad>' o 'at <Ciudad>'.
    Se puede mejorar con expresiones regulares más elaboradas o NLP.
    """
    pattern = r"\b(?:in|at)\s([A-Z][a-zA-Z]+(?:\s[A-Z][a-zA-Z]+)*)"
    matches = re.findall(pattern, text)
    return matches[0] if matches else None

def geocode_location(location_str):
    """Usa geopy + Nominatim para convertir texto en (lat, lon)."""
    try:
        time.sleep(1)  # Para no saturar el servicio
        loc = geolocator.geocode(location_str)
        if loc:
            return (loc.latitude, loc.longitude)
    except Exception as e:
        print(f"[ERROR] geocoding {location_str}: {e}")
    return None

def parse_feed(feed_url):
    """
    Lee un feed y extrae:
      - title
      - summary
      - link
      - published
      - image_url (si se provee)
      - lat, lon (si se detecta ubicación)
    """
    feed = feedparser.parse(feed_url)
    entries = []

    for e in feed.entries:
        title = getattr(e, 'title', 'No Title')
        summary = getattr(e, 'summary', '')
        link = getattr(e, 'link', '')
        published = getattr(e, 'published', '')

        # Extraer posible imagen (media_content o media_thumbnail)
        image_url = None
        if hasattr(e, 'media_content') and e.media_content:
            image_url = e.media_content[0].get('url')
        elif hasattr(e, 'media_thumbnail') and e.media_thumbnail:
            image_url = e.media_thumbnail[0].get('url')

        # Armar la entrada base
        new_entry = {
            "title": title,
            "summary": summary,
            "link": link,
            "published": published,
            "image_url": image_url,
            "lat": None,
            "lon": None
        }

        # Detectar ubicación si USE_GEOCODING está en True
        if USE_GEOCODING:
            full_text = f"{title} {summary}"
            possible_location = extract_possible_location(full_text)
            if possible_location:
                coords = geocode_location(possible_location)
                if coords:
                    new_entry["lat"] = coords[0]
                    new_entry["lon"] = coords[1]

        entries.append(new_entry)

    return entries

def generate_apa_citation(title, link, published):
    """Referencia APA7 básica."""
    return f"{title}. ({published}). [Blog post]. Recuperado de {link}"

def generate_geojson(master_data):
    """
    Crea un FeatureCollection con:
      - title
      - description (que combina summary truncado + enlace en formato uMap)
      - published
      - apa_citation
      - image_url
      - geometry con lat/lon
    """
    geojson_data = {
        "type": "FeatureCollection",
        "features": []
    }

    for item in master_data:
        lat = item.get("lat")
        lon = item.get("lon")
        if lat is not None and lon is not None:
            # Recortar summary a 200 chars si es muy largo
            summary = item.get("summary", "")
            if len(summary) > 200:
                summary = summary[:200] + "..."

            link = item.get("link", "")
            title = item.get("title", "No Title")
            published = item.get("published", "")
            image_url = item.get("image_url", None)

            # "description" con sintaxis de uMap para enlace clicable
            # Ej. "texto\n\n[[URL|Ver la fuente]]"
            description_text = f"{summary}\n\n[[{link}|Ver la fuente]]"

            feature = {
                "type": "Feature",
                "properties": {
                    "title": title,
                    "description": description_text,
                    "published": published,
                    "apa_citation": generate_apa_citation(title, link, published),
                    "image_url": image_url
                },
                "geometry": {
                    "type": "Point",
                    "coordinates": [lon, lat]
                }
            }
            geojson_data["features"].append(feature)

    return geojson_data

# ======================================
# 5. Script Principal
# ======================================
def main():
    # 1. Cargar o crear archivo maestro
    master_data = load_master_data()

    # 2. Recorrer todos los feeds
    for feed_url in RSS_FEEDS:
        print(f"[INFO] Leyendo feed: {feed_url}")
        new_entries = parse_feed(feed_url)
        for entry in new_entries:
            if not is_duplicate(entry, master_data):
                master_data.append(entry)

    # 3. Guardar master_data unificado
    save_master_data(master_data)

    # 4. Generar el GeoJSON final
    geojson_data = generate_geojson(master_data)
    with open(OUTPUT_GEOJSON, "w", encoding="utf-8") as f:
        json.dump(geojson_data, f, ensure_ascii=False, indent=2)

    print(f"\n[OK] ¡Archivo GeoJSON creado! -> {OUTPUT_GEOJSON}")
    print("[INFO] Revisa 'Files' en Colab para descargarlo (y el master_data.json).")

if __name__ == "__main__":
    main()
